
%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
11pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
%twoside, % Two page layout (page indentation for binding and different headers)
headinclude,footinclude, % Extra spacing for the header and footer
BCOR5mm, % Binding correction
]{scrartcl}

\input{structure.tex} % Include the structure.tex file which specified the document structure and layout

\hyphenation{Fortran hy-phen-ation} % Specify custom hyphenation points in words with dashes where you would like hyphenation to occur, or alternatively, don't put any dashes in a word to stop hyphenation altogether

%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR(S)
%----------------------------------------------------------------------------------------

\title{\normalfont\spacedallcaps{Daniel Ritchie}} % The article title

\author{\spacedallcaps{Research Statement}} % The article author(s) - author affiliations need to be specified in the AUTHOR AFFILIATIONS block

\date{} % An optional date to appear under the author(s)



\begin{document}

%----------------------------------------------------------------------------------------
%	HEADERS
%----------------------------------------------------------------------------------------

\pagestyle{scrheadings}
\clearscrheadings
\newcommand{\headertext}{\spacedlowsmallcaps{\color{black} Daniel Ritchie \color{halfgray} Research Statement}}
\ohead{\headertext}
\cfoot[\pagemark]{\pagemark}


\maketitle

My research focuses on solving complex procedural modeling and design problems using probabilistic programming. My work is interdisciplinary, sitting at the intersection of computer graphics, artificial intelligence, and programming languages. I believe in developing general-purpose solutions, rather than specialized fixes for one problem or application domain. This means that on the way to solving computer graphics problems, my work often leads to systems and algorithms that have broader impact for probabilistic programming and probabilistic inference in general.

In procedural modeling and design, content creators write programs that pseudo-randomly generate visual content, such as 3D models, websites, or arrangements of furniture. This approach allows designers to rapidly create and explore alternative design possibilities. It also scales to creating large amounts of diverse content without extensive human effort, which is becoming more important as the virtual worlds of films, games, and simulations grow larger and more detailed. Traditional procedural modeling tools operate via forward reasoning: the user writes a step-by-step recipe for generating content, such as a 3D model for a house. However, detailed, realistic content must also satisfy properties that are difficult to guarantee constructively---for example, the house models should be structurally stable. Satisfying such conditions seems to require \emph{inverse} reasoning, working backwards from the desired result.

Bayesian probabilistic inference provides a well-studied conceptual mechanism for this kind of inversion: the forward recipe serves as a generative prior distribution, and the desired properties can be encouraged via a likelihood function. Probabilistic programs are a natural choice for representing these types of distributions. They are a Turing-complete, universal family of probabilistic models, so they can capture the highly structured, recursive, mixed-continuous-discrete nature of many procedural models~\cite{Church}. They are also human-readable and human-writable and require little-to-no special expertise in probabilistic inference to author or understand.

Unfortunately, the expressiveness of probabilistic programs comes at a cost: inference on such complex programs is often intractable. We must resort to approximate methods that converge slowly, if at all. Thus, most of my work has focused on improving the reliability and runtime efficiency of probabilistic programming inference, with a particular eye towards procedural modeling applications in computer graphics. My research in this space has involved both algorithmic work (increasing the statistical efficiency of inference through new or improved algorithms) as well as systems work (making existing inference algorithms more computationally efficient).


% Following sections are all structured as: problem/opportunity, solution, result/impact

\section*{Eliminating redundant computation with C3}

The `Lightweight MH' variant of the Metropolis Hastings algorithm is a popular technique for implementing probabilistic programming inference~\cite{Lightweight}. It is easy to implement and can be embedded in an existing deterministic language, rather than requiring its own specialized interpreter or compiler. And it operates on arbitrary programs, including the complex programs found in procedural modeling and design applications. Unfortunately, it is also inefficient: every Metropolis Hastings proposal triggers a complete re-execution of the program, despite the fact that the changed variable often only affects a small subset of the program's execution trace. Probabilistic languages that run on custom interpreters often exploit this fact for faster inference, but they are complicated to implement and do not integrate as readily with existing deterministic code.

To get the best of both worlds---efficient, incrementalized proposals in a lightweight, embedded system---I developed a new MH implementation technique called C3~\cite{C3}. C3 leverages two insights. First, it transforms programs into continuation passing style (CPS): this makes continuations available at every point in the program, so execution can resume from anywhere. Second, C3 caches the receiver, inputs, and output of each function call, since many calls can be skipped when these quantities have not changed.

C3 significantly accelerates MH proposals. In the procedural modeling example below, where a tree-generating program is encouraged to take the target shape on the left, C3 runs nearly 10 times faster than Lightweight MH. Its two components, caching and CPS, work synergistically, delivering greater speedups when used together than the sum of their individual contributions. C3 also works well for many latent variable models in Bayesian data analysis, delivering 20-100x speedups on hidden Markov models, Gaussian mixtures, topic models, and hierarchical regression models.
\vspace{1em}
\newcommand*{\helvetica}{\fontfamily{phv}\selectfont}
\begin{figure*}[h!]
\centering
\setlength{\tabcolsep}{2pt}
\begin{tabular}{ccc}
	\includegraphics[width=0.25\linewidth]{figs/c3/target} &
	\includegraphics[width=0.25\linewidth]{figs/c3/result} &
	\shortstack{ \includegraphics[width=0.5\linewidth]{figs/c3/procmod_time} \\ \includegraphics[width=0.5\linewidth]{figs/c3/procmod_throughput} } \\
	{\helvetica \scriptsize{Target}} & {\helvetica \scriptsize{Output}} & 
\end{tabular}
\label{fig:c3_procmod}
\end{figure*}

\section*{Dealing with tight constraints using HMC}

Problems with single-site MH. Connection between tight constraints and data-induced strong variable coupling. HMC, statistical efficiency gain.

Also talk about how we implemented it in Quicksand, and how that provides computational efficiency, too.

\section*{Handling branching structure with SOSMC}

Motivate by talking about how MCMC gets stuck in structural local maxima, how SMC could avoid that problem entirely. Inspired by recent work adapting SMC to probabilistic programs. Have to handle `non-linear' programs with structured branching, as well as transdimensionality. Have to linearize call tree. Linearization affects SMC performance. Development of SOSMC. Stochastic future. Cool results.


\section*{Future research agenda}

Making inference more real-time (mention some cool examples of real-time constrained content generation that we'd like to achieve). Talk about amortized inference as an idea. Specifically talk about variational inference as a mechanism for achieving it. Mention/cite recent work in using neural networks to build recognition models. But need further work to make these work with structure-changing models, and with constraints not derived from data.

Inference is too much a `batch operation'---we need to account for the presence of the human user. More interactivity. Programs should react to user input / new data; FRP ideas. Also, mixed-initiative (or is the phrase I'm looking for mixed-modality?) programming, where user sometimes writes code and sometimes specifies examples / does direct manipulation, and the system infers code from that interaction.

Exploring connections to nearby disciplines. Procedural models as structured priors for computer vision, 3D reconstruction. Can also be viewed as a form of `content creation by scanning the world.' Also, real-time inference has other applications in time-constrained / resource-limited environments. Examples include building programmable embedded systems for doing sensing/inference. Would be useful in robotics, also just as a DIY thing for people to put around their houses, etc.


\bibliographystyle{plain}
\bibliography{research}


\end{document}